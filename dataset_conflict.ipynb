{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inizio lo scraping per i documenti dal 47970 al 47990...\n",
      "Processo il documento 47970...\n",
      "Documento 47970 salvato in: /home/sylcherry/UNIVDA/downloads/47970.txt\n",
      "Processo il documento 47971...\n",
      "Documento 47971 salvato in: /home/sylcherry/UNIVDA/downloads/47971.txt\n",
      "Processo il documento 47972...\n",
      "Documento 47972 non trovato (HTTP 404).\n",
      "Processo il documento 47973...\n",
      "Documento 47973 non trovato (HTTP 404).\n",
      "Processo il documento 47974...\n",
      "Documento 47974 non trovato (HTTP 404).\n",
      "Processo il documento 47975...\n",
      "Documento 47975 non trovato (HTTP 404).\n",
      "Processo il documento 47976...\n",
      "Documento 47976 non trovato (HTTP 404).\n",
      "Processo il documento 47977...\n",
      "Documento 47977 non trovato (HTTP 404).\n",
      "Processo il documento 47978...\n",
      "Documento 47978 non trovato (HTTP 404).\n",
      "Processo il documento 47979...\n",
      "Documento 47979 non trovato (HTTP 404).\n",
      "Processo il documento 47980...\n",
      "Documento 47980 non trovato (HTTP 404).\n",
      "Processo il documento 47981...\n",
      "Documento 47981 salvato in: /home/sylcherry/UNIVDA/downloads/47981.txt\n",
      "Processo il documento 47982...\n",
      "Documento 47982 salvato in: /home/sylcherry/UNIVDA/downloads/47982.txt\n",
      "Processo il documento 47983...\n",
      "Documento 47983 salvato in: /home/sylcherry/UNIVDA/downloads/47983.txt\n",
      "Processo il documento 47984...\n",
      "Documento 47984 salvato in: /home/sylcherry/UNIVDA/downloads/47984.txt\n",
      "Processo il documento 47985...\n",
      "Documento 47985 salvato in: /home/sylcherry/UNIVDA/downloads/47985.txt\n",
      "Processo il documento 47986...\n",
      "Documento 47986 salvato in: /home/sylcherry/UNIVDA/downloads/47986.txt\n",
      "Processo il documento 47987...\n",
      "Documento 47987 salvato in: /home/sylcherry/UNIVDA/downloads/47987.txt\n",
      "Processo il documento 47988...\n",
      "Documento 47988 salvato in: /home/sylcherry/UNIVDA/downloads/47988.txt\n",
      "Processo il documento 47989...\n",
      "Documento 47989 salvato in: /home/sylcherry/UNIVDA/downloads/47989.txt\n",
      "Processo il documento 47990...\n",
      "Documento 47990 salvato in: /home/sylcherry/UNIVDA/downloads/47990.txt\n",
      "Salvataggio dei risultati nel file CSV: csv_paths.csv\n",
      "Completato! Tutti i documenti salvati nella cartella: /home/sylcherry/UNIVDA/downloads\n"
     ]
    }
   ],
   "source": [
    "BASE_URL = \"https://www.consiglio.vda.it/app/oggettidelconsiglio/dettaglio?pk_documento={}&versione=R\"\n",
    "\n",
    "OUTPUT_FOLDER = \"/home/sylcherry/UNIVDA/downloads\"\n",
    "if not os.path.exists(OUTPUT_FOLDER):\n",
    "    os.makedirs(OUTPUT_FOLDER)\n",
    "\n",
    "#funzione per scraperare e salvare i resoconti dal sito del consiglio Valle\n",
    "def scrape_and_save(doc_id):\n",
    "    \"\"\"\n",
    "    Scarica e salva il contenuto della pagina come file di testo.\n",
    "    \"\"\"\n",
    "    url = BASE_URL.format(doc_id)\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Documento {doc_id} non trovato (HTTP {response.status_code}).\")\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    page_text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "    output_file = os.path.join(OUTPUT_FOLDER, f\"{doc_id}.txt\")\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(page_text)\n",
    "    \n",
    "    print(f\"Documento {doc_id} salvato in: {output_file}\")\n",
    "    return output_file\n",
    "\n",
    "def main(start_id, end_id):\n",
    "    \"\"\"\n",
    "    Itera sugli ID dei documenti, scarica le pagine e le salva come file di testo.\n",
    "    Genera un file CSV con i percorsi salvati.\n",
    "    \"\"\"\n",
    "    csv_data = []\n",
    "\n",
    "    print(f\"Inizio lo scraping per i documenti dal {start_id} al {end_id}...\")\n",
    "    for doc_id in range(start_id, end_id + 1):\n",
    "        print(f\"Processo il documento {doc_id}...\")\n",
    "        file_path = scrape_and_save(doc_id)\n",
    "        if file_path:\n",
    "            csv_data.append({\"ID_file\": doc_id, \"path_src\": file_path})\n",
    "\n",
    "    csv_file = \"csv_paths.csv\"\n",
    "    print(f\"Salvataggio dei risultati nel file CSV: {csv_file}\")\n",
    "    with open(csv_file, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=[\"ID_file\", \"path_src\"])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(csv_data)\n",
    "\n",
    "    print(\"Completato! Tutti i documenti salvati nella cartella:\", OUTPUT_FOLDER)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(start_id=47970, end_id=47990)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funzione per pulire i file txt dalle parti inutili presenti nella pagina web del consiglio Valle\n",
    "def first_clean(target_folder, keyword, mid_strings, end_keyword, csv_paths):\n",
    "    df = pd.read_csv(csv_paths)\n",
    "\n",
    "    if not os.path.exists(target_folder):\n",
    "        os.makedirs(target_folder)\n",
    "\n",
    "    df[\"path_clean\"] = \"\"\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        source_path = row[\"path_src\"]\n",
    "        if source_path.endswith(\".txt\"):\n",
    "            filename = os.path.basename(source_path)\n",
    "            target_path = os.path.join(target_folder, filename)\n",
    "\n",
    "            df.at[idx, \"path_clean\"] = target_path\n",
    "\n",
    "            with open(source_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                content = file.read()\n",
    "\n",
    "            if keyword in content:\n",
    "                content = keyword + content.split(keyword, 1)[1] \n",
    "\n",
    "            for mid_string in mid_strings:\n",
    "                content = re.sub(re.escape(mid_string), \"\", content) \n",
    "\n",
    "            if end_keyword in content:\n",
    "                content = content.split(end_keyword, 1)[0]  \n",
    "\n",
    "            with open(target_path, \"w\", encoding=\"utf-8\") as file:\n",
    "                file.write(content)\n",
    "\n",
    "    df.to_csv(csv_paths, index=False)\n",
    "\n",
    "#funzione per estrarre informazioni dai file txt: oggetto, legislatura e classificazione\n",
    "def first_info(pattern1, pattern2, csv_paths, csv_details):\n",
    "    df_paths = pd.read_csv(csv_paths)\n",
    "    df_details = pd.DataFrame({'ID_file': df_paths['ID_file']})\n",
    "\n",
    "    df_details['object'] = \"\"\n",
    "    df_details['legislature'] = \"\"\n",
    "    df_details['class'] = \"\"\n",
    "\n",
    "    for idx, row in df_paths.iterrows():\n",
    "        source_path = row[\"path_clean\"]\n",
    "        if source_path.endswith(\".txt\"):\n",
    "            filename = os.path.basename(source_path)\n",
    "            filenum = int(os.path.splitext(filename)[0])\n",
    "\n",
    "            with open(source_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                content = file.read()\n",
    "\n",
    "            match1 = re.search(pattern1, content)\n",
    "\n",
    "            if match1:\n",
    "                stringa = match1.group(1).strip()\n",
    "                ogg, leg = stringa.split(\"/\", 1)\n",
    "\n",
    "                df_details.loc[df_details['ID_file'] == filenum, 'object'] = ogg\n",
    "                df_details.loc[df_details['ID_file'] == filenum, 'legislature'] = leg\n",
    "\n",
    "            match2 = re.search(pattern2, content, re.DOTALL)\n",
    "            \n",
    "            if match2:\n",
    "                classe = match2.group(1).strip()\n",
    "                classe = classe.replace(\"\\n\", \", \").strip()\n",
    "                df_details.loc[df_details['ID_file'] == filenum, 'class'] = classe\n",
    "\n",
    "    df_details.to_csv(csv_details, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_folder = \"/home/sylcherry/UNIVDA/clean\"\n",
    "\n",
    "csv_paths = \"/home/sylcherry/UNIVDA/csv_paths.csv\"\n",
    "csv_details = \"/home/sylcherry/UNIVDA/csv_details.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = \"Classificazione\"\n",
    "mid_strings = [\"Precedente\", \"Successivo\", \"Resoconto integrale del dibattito dell'aula. I documenti allegati sono reperibili nel link \\\"iter atto\\\".\"]\n",
    "end_keyword = \"Informativa cookies\"\n",
    "\n",
    "first_clean(target_folder, keyword, mid_strings, end_keyword, csv_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern1 = r'(?:OGGETTO N\\.|OBJET NÂ°)(.*?)\\s*-'\n",
    "pattern2 = r'Classificazione\\s*(.*?)\\s*Oggetto'\n",
    "\n",
    "first_info(pattern1, pattern2, csv_paths, csv_details)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
