{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inizio lo scraping per i documenti dal 47990 al 47990...\n",
      "Processo il documento 47990...\n",
      "Documento 47990 salvato in: ./downloads/47990.txt\n",
      "Salvataggio dei risultati nel file CSV: csv_paths.csv\n",
      "Completato! Tutti i documenti salvati nella cartella: ./downloads\n"
     ]
    }
   ],
   "source": [
    "BASE_URL = \"https://www.consiglio.vda.it/app/oggettidelconsiglio/dettaglio?pk_documento={}&versione=R\"\n",
    "\n",
    "OUTPUT_FOLDER = \"./downloads\"\n",
    "if not os.path.exists(OUTPUT_FOLDER):\n",
    "    os.makedirs(OUTPUT_FOLDER)\n",
    "\n",
    "#funzione per scraperare e salvare i resoconti dal sito del consiglio Valle\n",
    "def scrape_and_save(doc_id):\n",
    "    url = BASE_URL.format(doc_id)\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Documento {doc_id} non trovato (HTTP {response.status_code}).\")\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    page_text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "    output_file = os.path.join(OUTPUT_FOLDER, f\"{doc_id}.txt\")\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(page_text)\n",
    "    \n",
    "    print(f\"Documento {doc_id} salvato in: {output_file}\")\n",
    "    return output_file\n",
    "\n",
    "def main(start_id, end_id):\n",
    "    csv_data = []\n",
    "\n",
    "    print(f\"Inizio lo scraping per i documenti dal {start_id} al {end_id}...\")\n",
    "    for doc_id in range(start_id, end_id + 1):\n",
    "        print(f\"Processo il documento {doc_id}...\")\n",
    "        file_path = scrape_and_save(doc_id)\n",
    "        if file_path:\n",
    "            csv_data.append({\"ID_file\": doc_id, \"path_src\": file_path})\n",
    "\n",
    "    csv_file = \"csv_paths.csv\"\n",
    "    print(f\"Salvataggio dei risultati nel file CSV: {csv_file}\")\n",
    "    with open(csv_file, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=[\"ID_file\", \"path_src\"])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(csv_data)\n",
    "\n",
    "    print(\"Completato! Tutti i documenti salvati nella cartella:\", OUTPUT_FOLDER)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(start_id=47990, end_id=47990)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funzione per pulire i file txt dalle parti inutili presenti nella pagina web del consiglio Valle\n",
    "def first_clean(target_folder, keyword, mid_strings, end_keyword, csv_paths):\n",
    "    df = pd.read_csv(csv_paths)\n",
    "\n",
    "    if not os.path.exists(target_folder):\n",
    "        os.makedirs(target_folder)\n",
    "\n",
    "    df[\"path_clean\"] = \"\"\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        source_path = row[\"path_src\"]\n",
    "        if source_path.endswith(\".txt\"):\n",
    "            filename = os.path.basename(source_path)\n",
    "            target_path = os.path.join(target_folder, filename)\n",
    "\n",
    "            df.at[idx, \"path_clean\"] = target_path\n",
    "\n",
    "            with open(source_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                content = file.read()\n",
    "\n",
    "            if keyword in content:\n",
    "                content = keyword + content.split(keyword, 1)[1] \n",
    "\n",
    "            for mid_string in mid_strings:\n",
    "                content = re.sub(re.escape(mid_string), \"\", content) \n",
    "\n",
    "            if end_keyword in content:\n",
    "                content = content.split(end_keyword, 1)[0]  \n",
    "\n",
    "            with open(target_path, \"w\", encoding=\"utf-8\") as file:\n",
    "                file.write(content)\n",
    "\n",
    "    df.to_csv(csv_paths, index=False)\n",
    "\n",
    "#funzione per estrarre informazioni dai file txt: oggetto, legislatura e classificazione\n",
    "def first_info(pattern1, pattern2, pattern3, csv_paths):\n",
    "    df_paths = pd.read_csv(csv_paths)\n",
    "\n",
    "    df_paths['language'] = \"\"\n",
    "    df_paths['object'] = \"\"\n",
    "    df_paths['legislature'] = \"\"\n",
    "    df_paths['class'] = \"\"\n",
    "\n",
    "    for idx, row in df_paths.iterrows():\n",
    "        source_path = row[\"path_clean\"]\n",
    "        if source_path.endswith(\".txt\"):\n",
    "            filename = os.path.basename(source_path)\n",
    "            filenum = int(os.path.splitext(filename)[0])\n",
    "\n",
    "            with open(source_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                content = file.read()\n",
    "\n",
    "            match1 = re.search(pattern1, content)\n",
    "\n",
    "            if match1:\n",
    "                stringa = match1.group(1).strip()\n",
    "                ogg, leg = stringa.split(\"/\", 1)\n",
    "\n",
    "                df_paths.loc[df_paths['ID_file'] == filenum, 'object'] = ogg\n",
    "                df_paths.loc[df_paths['ID_file'] == filenum, 'legislature'] = leg\n",
    "\n",
    "            match2 = re.search(pattern2, content, re.DOTALL)\n",
    "            \n",
    "            if match2:\n",
    "                classe = match2.group(1).strip()\n",
    "                classe = classe.replace(\"\\n\", \", \").strip()\n",
    "                df_paths.loc[df_paths['ID_file'] == filenum, 'class'] = classe\n",
    "\n",
    "            match3 = re.search(pattern3, content)\n",
    "\n",
    "            if match3:\n",
    "                lang = 'fr'\n",
    "            else:\n",
    "                lang = 'it'\n",
    "            df_paths.loc[df_paths['ID_file'] == filenum, 'language'] = lang\n",
    "\n",
    "    df_paths.to_csv(csv_paths, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_folder = \"./clean\"\n",
    "\n",
    "csv_paths = \"./csv_paths.csv\"\n",
    "csv_details = \"./csv_details.csv\"\n",
    "csv_cons = \"./csv_cons.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = \"Classificazione\"\n",
    "mid_strings = [\"Precedente\", \"Successivo\", \"Resoconto integrale del dibattito dell'aula. I documenti allegati sono reperibili nel link \\\"iter atto\\\".\"]\n",
    "end_keyword = \"Informativa cookies\"\n",
    "\n",
    "first_clean(target_folder, keyword, mid_strings, end_keyword, csv_paths)\n",
    "\n",
    "pattern1 = r'(?:OGGETTO N\\.|OBJET N°)(.*?)\\s*-'\n",
    "pattern2 = r'Classificazione\\s*(.*?)\\s*Oggetto'\n",
    "pattern3 = r'object'\n",
    "\n",
    "first_info(pattern1, pattern2, pattern3, csv_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def define_names(csv_cons, leg):\n",
    "    df_cons = pd.read_csv(csv_cons)\n",
    "    names = []\n",
    "\n",
    "    filtered_cons = df_cons[df_cons['legislature'].str.contains(leg, case=False, na=False)]\n",
    "    \n",
    "    surname_counts = filtered_cons['surname'].value_counts()\n",
    "\n",
    "    for idx, row in filtered_cons.iterrows():\n",
    "        surname = row[\"surname\"]\n",
    "        name = row[\"name\"]\n",
    "\n",
    "        if surname_counts[surname] > 1:\n",
    "            names.append(f\"{surname} {name[0]}.\")\n",
    "        else:\n",
    "            names.append(surname)\n",
    "    \n",
    "    return filtered_cons, names\n",
    "\n",
    "def isolate_chunk(csv_paths, csv_cons):\n",
    "    df_paths = pd.read_csv(csv_paths)\n",
    "    chunk_list = []\n",
    "\n",
    "    for idx, row in df_paths.iterrows():\n",
    "        leg = row[\"legislature\"]\n",
    "        language = row[\"language\"]\n",
    "        df_cons, list_cons = define_names(csv_cons, leg)\n",
    "\n",
    "        with open(row[\"path_clean\"], 'r') as f:\n",
    "            text = f.read()\n",
    "\n",
    "            start_pos = 0\n",
    "            chunk_idx = 1  # Indice crescente per ogni chunk\n",
    "\n",
    "            # Scorro su ogni entry della lista dei nomi\n",
    "            for i, name in enumerate(list_cons):\n",
    "                # Creiamo un pattern che cerca il nome, seguito dal partito tra parentesi e dal trattino\n",
    "                pattern = r\"(?i)\" + re.escape(name) + r\"\\s?\\([^\\)]*\\)\\s?-\"  # Regex per nome, partito, trattino\n",
    "                matches = list(re.finditer(pattern, text[start_pos:]))  # Trova tutte le occorrenze\n",
    "                print(matches)\n",
    "                \n",
    "                # Per ogni match del nome nel testo, estrai un nuovo chunk\n",
    "                for match in matches:\n",
    "                    # Trovo dove inizia il nuovo chunk\n",
    "                    start_pos = match.start() + len(match.group(0))  # Posizione dove inizia il chunk\n",
    "                    \n",
    "                    # Trovo la fine del chunk, che è la prossima occorrenza di un altro nome\n",
    "                    next_match = None\n",
    "                    if i + 1 < len(list_cons):\n",
    "                        next_match = re.search(re.escape(list_cons[i+1]), text[start_pos:], re.IGNORECASE)\n",
    "\n",
    "                    # La fine del chunk è la posizione di fine o il prossimo match\n",
    "                    end_pos = next_match.start() if next_match else len(text)\n",
    "\n",
    "                    # Estraggo il chunk\n",
    "                    chunk = text[start_pos:end_pos].strip()\n",
    "\n",
    "                    if chunk:  # Se il chunk non è vuoto\n",
    "                        # Trovo le informazioni relative al nome (cognome, nome, etc.)\n",
    "                        surname = name.split()[0]\n",
    "                        person_info = df_cons[df_cons[\"surname\"] == surname].iloc[0]\n",
    "                        first_name = person_info[\"name\"]\n",
    "                        year_birth = person_info[\"year_birth\"]\n",
    "                        gender = person_info[\"gender\"]\n",
    "                        group = person_info[\"group\"] if \"group\" in person_info else \"N/A\"  # Nel caso in cui il partito non sia presente\n",
    "\n",
    "                        # Aggiungo il chunk alla lista dei chunks\n",
    "                        chunk_list.append({\n",
    "                            \"ID_file\": row[\"ID_file\"],\n",
    "                            \"leg\": leg,\n",
    "                            \"class\": row[\"class\"],\n",
    "                            \"language\": language,\n",
    "                            \"surname\": surname,\n",
    "                            \"name\": first_name,\n",
    "                            \"year_birth\": year_birth,\n",
    "                            \"gender\": gender,\n",
    "                            \"group\": group,\n",
    "                            \"posizione_del_chunk\": chunk_idx,  # Indice crescente per ordinamento\n",
    "                            \"chunk\": chunk\n",
    "                        })\n",
    "\n",
    "                        chunk_idx += 1  # Incrementiamo l'indice del chunk\n",
    "\n",
    "                    # Aggiorniamo start_pos per il prossimo match\n",
    "                    start_pos = end_pos\n",
    "\n",
    "            # Se l'ultimo chunk non è stato preso, aggiungiamolo\n",
    "            if start_pos < len(text):  # Se c'è ancora del testo rimanente\n",
    "                chunk = text[start_pos:].strip()\n",
    "                if chunk:  # Evitiamo di aggiungere chunk vuoti\n",
    "                    chunk_list.append({\n",
    "                        \"ID_file\": row[\"ID_file\"],\n",
    "                        \"leg\": leg,\n",
    "                        \"class\": row[\"class\"],\n",
    "                        \"language\": language,\n",
    "                        \"surname\": \"\",  # Nessun nome specifico per l'ultimo chunk\n",
    "                        \"name\": \"\",\n",
    "                        \"year_birth\": \"\",\n",
    "                        \"gender\": \"\",\n",
    "                        \"group\": \"\",\n",
    "                        \"posizione_del_chunk\": chunk_idx,\n",
    "                        \"chunk\": chunk\n",
    "                    })\n",
    "\n",
    "    # Creiamo il DataFrame finale con tutti i chunks\n",
    "    df_chunks = pd.DataFrame(chunk_list)\n",
    "    return df_chunks\n",
    "\n",
    "# Supponiamo che i percorsi ai file siano definiti\n",
    "df = isolate_chunk(csv_paths, csv_cons)\n",
    "\n",
    "# Visualizza l'output\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aggravi', 'Baccega', 'Barmasse', 'Bertin', 'Bertschy', 'Brunod', 'Carrel', 'Caveri', 'Chatrian', 'Cretier', 'Di Marco', 'Distort', 'Foudraz', 'Ganis', 'Grosjacques', 'Guichardaz E.', 'Guichardaz J.', 'Jordan', 'Lavevaz', 'Lavy', 'Lucianaz', 'Malacrinò', 'Manfrin', 'Marguerettaz', 'Marquis', 'Marzi', 'Minelli', 'Padovani', 'Perron', 'Planaz', 'Restano', 'Rollandin', 'Rosaire', 'Sammaritani', 'Sapinet', 'Spelgatti', 'Stevenin', 'Testolin']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_file</th>\n",
       "      <th>leg</th>\n",
       "      <th>class</th>\n",
       "      <th>language</th>\n",
       "      <th>surname</th>\n",
       "      <th>name</th>\n",
       "      <th>year_birth</th>\n",
       "      <th>gender</th>\n",
       "      <th>group</th>\n",
       "      <th>posizione_del_chunk</th>\n",
       "      <th>chunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47990</td>\n",
       "      <td>XVI</td>\n",
       "      <td>ENTI LOCALI, Comuni</td>\n",
       "      <td>it</td>\n",
       "      <td>Bertin</td>\n",
       "      <td>Alberto</td>\n",
       "      <td>1966</td>\n",
       "      <td>M</td>\n",
       "      <td>N/A</td>\n",
       "      <td>1</td>\n",
       "      <td>Punto n. 7 all'ordine del giorno.\\nPer illustr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47990</td>\n",
       "      <td>XVI</td>\n",
       "      <td>ENTI LOCALI, Comuni</td>\n",
       "      <td>it</td>\n",
       "      <td>Lavy</td>\n",
       "      <td>Erik</td>\n",
       "      <td>1995</td>\n",
       "      <td>M</td>\n",
       "      <td>N/A</td>\n",
       "      <td>2</td>\n",
       "      <td>La presente proposta di legge tratta di\\nmisur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47990</td>\n",
       "      <td>XVI</td>\n",
       "      <td>ENTI LOCALI, Comuni</td>\n",
       "      <td>it</td>\n",
       "      <td>Restano</td>\n",
       "      <td>Claudio</td>\n",
       "      <td>1964</td>\n",
       "      <td>M</td>\n",
       "      <td>N/A</td>\n",
       "      <td>3</td>\n",
       "      <td>Intervengo a nome del gruppo di\\nRassemblement...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47990</td>\n",
       "      <td>XVI</td>\n",
       "      <td>ENTI LOCALI, Comuni</td>\n",
       "      <td>it</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>Corrado</td>\n",
       "      <td>1973</td>\n",
       "      <td>M</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4</td>\n",
       "      <td>A integrazione di quanto è stato detto,\\ncredi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47990</td>\n",
       "      <td>XVI</td>\n",
       "      <td>ENTI LOCALI, Comuni</td>\n",
       "      <td>it</td>\n",
       "      <td>Minelli</td>\n",
       "      <td>Chiara</td>\n",
       "      <td>1966</td>\n",
       "      <td>F</td>\n",
       "      <td>N/A</td>\n",
       "      <td>5</td>\n",
       "      <td>Abbiamo letto già tempo fa la proposta\\ndei co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>47990</td>\n",
       "      <td>XVI</td>\n",
       "      <td>ENTI LOCALI, Comuni</td>\n",
       "      <td>it</td>\n",
       "      <td>Chatrian</td>\n",
       "      <td>Albert</td>\n",
       "      <td>1975</td>\n",
       "      <td>M</td>\n",
       "      <td>N/A</td>\n",
       "      <td>6</td>\n",
       "      <td>Mi associo ai ringraziamenti, collega\\nLavy, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>47990</td>\n",
       "      <td>XVI</td>\n",
       "      <td>ENTI LOCALI, Comuni</td>\n",
       "      <td>it</td>\n",
       "      <td>Perron</td>\n",
       "      <td>Simone</td>\n",
       "      <td>1979</td>\n",
       "      <td>M</td>\n",
       "      <td>N/A</td>\n",
       "      <td>7</td>\n",
       "      <td>Interverrò brevemente, anche\\ncogliendo lo spu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>47990</td>\n",
       "      <td>XVI</td>\n",
       "      <td>ENTI LOCALI, Comuni</td>\n",
       "      <td>it</td>\n",
       "      <td>Lavy</td>\n",
       "      <td>Erik</td>\n",
       "      <td>1995</td>\n",
       "      <td>M</td>\n",
       "      <td>N/A</td>\n",
       "      <td>8</td>\n",
       "      <td>Ringrazio i colleghi per il dibattito.\\nAndrò ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>47990</td>\n",
       "      <td>XVI</td>\n",
       "      <td>ENTI LOCALI, Comuni</td>\n",
       "      <td>it</td>\n",
       "      <td>Caveri</td>\n",
       "      <td>Luciano Emilio</td>\n",
       "      <td>1958</td>\n",
       "      <td>M</td>\n",
       "      <td>N/A</td>\n",
       "      <td>9</td>\n",
       "      <td>Interverrà anche il Presidente, io mi\\nlimiter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>47990</td>\n",
       "      <td>XVI</td>\n",
       "      <td>ENTI LOCALI, Comuni</td>\n",
       "      <td>it</td>\n",
       "      <td>Testolin</td>\n",
       "      <td>Renzo</td>\n",
       "      <td>1968</td>\n",
       "      <td>M</td>\n",
       "      <td>N/A</td>\n",
       "      <td>10</td>\n",
       "      <td>Credo che a valle dell'ultimo intervento\\ndel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>47990</td>\n",
       "      <td>XVI</td>\n",
       "      <td>ENTI LOCALI, Comuni</td>\n",
       "      <td>it</td>\n",
       "      <td>Ganis</td>\n",
       "      <td>Christian</td>\n",
       "      <td>1973</td>\n",
       "      <td>M</td>\n",
       "      <td>N/A</td>\n",
       "      <td>11</td>\n",
       "      <td>Ringrazio gli intervenuti e i proponenti di\\nq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>47990</td>\n",
       "      <td>XVI</td>\n",
       "      <td>ENTI LOCALI, Comuni</td>\n",
       "      <td>it</td>\n",
       "      <td>Lavy</td>\n",
       "      <td>Erik</td>\n",
       "      <td>1995</td>\n",
       "      <td>M</td>\n",
       "      <td>N/A</td>\n",
       "      <td>12</td>\n",
       "      <td>Grazie, Presidente, per le ultime\\nconsiderazi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>47990</td>\n",
       "      <td>XVI</td>\n",
       "      <td>ENTI LOCALI, Comuni</td>\n",
       "      <td>it</td>\n",
       "      <td>Perron</td>\n",
       "      <td>Simone</td>\n",
       "      <td>1979</td>\n",
       "      <td>M</td>\n",
       "      <td>N/A</td>\n",
       "      <td>13</td>\n",
       "      <td>Ovviamente voterò positivamente per\\nquesta le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>47990</td>\n",
       "      <td>XVI</td>\n",
       "      <td>ENTI LOCALI, Comuni</td>\n",
       "      <td>it</td>\n",
       "      <td>Cretier</td>\n",
       "      <td>Paolo</td>\n",
       "      <td>1963</td>\n",
       "      <td>M</td>\n",
       "      <td>N/A</td>\n",
       "      <td>14</td>\n",
       "      <td>Sarò molto breve vista l'ora e vista la\\ndiscu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>47990</td>\n",
       "      <td>XVI</td>\n",
       "      <td>ENTI LOCALI, Comuni</td>\n",
       "      <td>it</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "      <td>Sarò molto breve vista l'ora e vista la\\ndiscu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_file  leg                class language   surname            name  \\\n",
       "0     47990  XVI  ENTI LOCALI, Comuni       it    Bertin         Alberto   \n",
       "1     47990  XVI  ENTI LOCALI, Comuni       it      Lavy            Erik   \n",
       "2     47990  XVI  ENTI LOCALI, Comuni       it   Restano         Claudio   \n",
       "3     47990  XVI  ENTI LOCALI, Comuni       it    Jordan         Corrado   \n",
       "4     47990  XVI  ENTI LOCALI, Comuni       it   Minelli          Chiara   \n",
       "5     47990  XVI  ENTI LOCALI, Comuni       it  Chatrian          Albert   \n",
       "6     47990  XVI  ENTI LOCALI, Comuni       it    Perron          Simone   \n",
       "7     47990  XVI  ENTI LOCALI, Comuni       it      Lavy            Erik   \n",
       "8     47990  XVI  ENTI LOCALI, Comuni       it    Caveri  Luciano Emilio   \n",
       "9     47990  XVI  ENTI LOCALI, Comuni       it  Testolin           Renzo   \n",
       "10    47990  XVI  ENTI LOCALI, Comuni       it     Ganis       Christian   \n",
       "11    47990  XVI  ENTI LOCALI, Comuni       it      Lavy            Erik   \n",
       "12    47990  XVI  ENTI LOCALI, Comuni       it    Perron          Simone   \n",
       "13    47990  XVI  ENTI LOCALI, Comuni       it   Cretier           Paolo   \n",
       "14    47990  XVI  ENTI LOCALI, Comuni       it                             \n",
       "\n",
       "   year_birth gender group  posizione_del_chunk  \\\n",
       "0        1966      M   N/A                    1   \n",
       "1        1995      M   N/A                    2   \n",
       "2        1964      M   N/A                    3   \n",
       "3        1973      M   N/A                    4   \n",
       "4        1966      F   N/A                    5   \n",
       "5        1975      M   N/A                    6   \n",
       "6        1979      M   N/A                    7   \n",
       "7        1995      M   N/A                    8   \n",
       "8        1958      M   N/A                    9   \n",
       "9        1968      M   N/A                   10   \n",
       "10       1973      M   N/A                   11   \n",
       "11       1995      M   N/A                   12   \n",
       "12       1979      M   N/A                   13   \n",
       "13       1963      M   N/A                   14   \n",
       "14                                           15   \n",
       "\n",
       "                                                chunk  \n",
       "0   Punto n. 7 all'ordine del giorno.\\nPer illustr...  \n",
       "1   La presente proposta di legge tratta di\\nmisur...  \n",
       "2   Intervengo a nome del gruppo di\\nRassemblement...  \n",
       "3   A integrazione di quanto è stato detto,\\ncredi...  \n",
       "4   Abbiamo letto già tempo fa la proposta\\ndei co...  \n",
       "5   Mi associo ai ringraziamenti, collega\\nLavy, p...  \n",
       "6   Interverrò brevemente, anche\\ncogliendo lo spu...  \n",
       "7   Ringrazio i colleghi per il dibattito.\\nAndrò ...  \n",
       "8   Interverrà anche il Presidente, io mi\\nlimiter...  \n",
       "9   Credo che a valle dell'ultimo intervento\\ndel ...  \n",
       "10  Ringrazio gli intervenuti e i proponenti di\\nq...  \n",
       "11  Grazie, Presidente, per le ultime\\nconsiderazi...  \n",
       "12  Ovviamente voterò positivamente per\\nquesta le...  \n",
       "13  Sarò molto breve vista l'ora e vista la\\ndiscu...  \n",
       "14  Sarò molto breve vista l'ora e vista la\\ndiscu...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def define_names(csv_cons, leg):\n",
    "    df_cons = pd.read_csv(csv_cons)\n",
    "    names = []\n",
    "\n",
    "    filtered_cons = df_cons[df_cons['legislature'].str.contains(leg, case=False, na=False)]\n",
    "    \n",
    "    surname_counts = filtered_cons['surname'].value_counts()\n",
    "\n",
    "    for idx, row in filtered_cons.iterrows():\n",
    "        surname = row[\"surname\"]\n",
    "        name = row[\"name\"]\n",
    "\n",
    "        if surname_counts[surname] > 1:\n",
    "            names.append(f\"{surname} {name[0]}.\")\n",
    "        else:\n",
    "            names.append(surname)\n",
    "    print(names)\n",
    "    return filtered_cons, names\n",
    "\n",
    "def isolate_chunk(csv_paths, csv_cons):\n",
    "    df_paths = pd.read_csv(csv_paths)\n",
    "    chunk_list = []\n",
    "\n",
    "    for idx, row in df_paths.iterrows():\n",
    "        leg = row[\"legislature\"]\n",
    "        language = row[\"language\"]\n",
    "        df_cons, list_cons = define_names(csv_cons, leg)\n",
    "\n",
    "        with open(row[\"path_clean\"], 'r') as f:\n",
    "            text = f.read()\n",
    "\n",
    "            # Troviamo tutti i match ordinati\n",
    "            all_matches = []\n",
    "            for name in list_cons:\n",
    "                pattern = r\"(?i)\" + re.escape(name) + r\"\\s?\\([^\\)]*\\)\\s?-\"\n",
    "                matches = list(re.finditer(pattern, text))\n",
    "                all_matches.extend(matches)\n",
    "\n",
    "            # Ordiniamo i match in base alla posizione\n",
    "            all_matches.sort(key=lambda match: match.start())\n",
    "\n",
    "            # Per ogni match, estraiamo un chunk\n",
    "            chunk_idx = 1\n",
    "            for i, match in enumerate(all_matches):\n",
    "                start_pos = match.end()  # Fine del nome, inizio del chunk\n",
    "                \n",
    "                # Troviamo la fine del chunk usando il prossimo match\n",
    "                end_pos = all_matches[i + 1].start() if i + 1 < len(all_matches) else len(text)\n",
    "\n",
    "                # Estraggo il chunk dal testo\n",
    "                chunk = text[start_pos:end_pos].strip()\n",
    "\n",
    "                if chunk:  # Se il chunk non è vuoto\n",
    "                    # Recupero le informazioni sul deputato\n",
    "                    surname = match.group(0).split()[0]  # Cognome dal match\n",
    "                    person_info = df_cons[df_cons[\"surname\"] == surname].iloc[0]\n",
    "                    first_name = person_info[\"name\"]\n",
    "                    year_birth = person_info[\"year_birth\"]\n",
    "                    gender = person_info[\"gender\"]\n",
    "                    group = person_info[\"group\"] if \"group\" in person_info else \"N/A\"\n",
    "\n",
    "                    # Aggiungo il chunk alla lista\n",
    "                    chunk_list.append({\n",
    "                        \"ID_file\": row[\"ID_file\"],\n",
    "                        \"leg\": leg,\n",
    "                        \"class\": row[\"class\"],\n",
    "                        \"language\": language,\n",
    "                        \"surname\": surname,\n",
    "                        \"name\": first_name,\n",
    "                        \"year_birth\": year_birth,\n",
    "                        \"gender\": gender,\n",
    "                        \"group\": group,\n",
    "                        \"posizione_del_chunk\": chunk_idx,\n",
    "                        \"chunk\": chunk\n",
    "                    })\n",
    "\n",
    "                    chunk_idx += 1\n",
    "\n",
    "            # Gestione dell'ultimo chunk (se presente)\n",
    "            if all_matches:  # Controlliamo che ci siano match\n",
    "                last_match_end = all_matches[-1].end()  # Fine dell'ultimo match\n",
    "                if last_match_end < len(text):  # Se c'è testo residuo dopo l'ultimo match\n",
    "                    chunk = text[last_match_end:].strip()\n",
    "                    if chunk:  # Evitiamo di aggiungere chunk vuoti\n",
    "                        chunk_list.append({\n",
    "                            \"ID_file\": row[\"ID_file\"],\n",
    "                            \"leg\": leg,\n",
    "                            \"class\": row[\"class\"],\n",
    "                            \"language\": language,\n",
    "                            \"surname\": \"\",  # Nessun nome specifico\n",
    "                            \"name\": \"\",\n",
    "                            \"year_birth\": \"\",\n",
    "                            \"gender\": \"\",\n",
    "                            \"group\": \"\",\n",
    "                            \"posizione_del_chunk\": chunk_idx,\n",
    "                            \"chunk\": chunk\n",
    "                        })\n",
    "\n",
    "    # Creiamo il DataFrame finale con tutti i chunks\n",
    "    df_chunks = pd.DataFrame(chunk_list)\n",
    "    return df_chunks\n",
    "\n",
    "# Supponiamo che i percorsi ai file siano definiti\n",
    "df = isolate_chunk(csv_paths, csv_cons)\n",
    "\n",
    "# Visualizza l'output\n",
    "df\n",
    "\n",
    "df.to_csv(\"csv_chunks.csv\", index=False)\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
