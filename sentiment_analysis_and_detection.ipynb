{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nrclex import NRCLex\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "from textblob.sentiments import PatternAnalyzer\n",
    "\n",
    "import eng_spacysentiment\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.nn.functional import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/sylcherry/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/home/sylcherry/.local/lib/python3.10/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'eng_spacysentiment' (2.3.0) was trained with spaCy v3.5.3 and may not be 100% compatible with the current version (3.7.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "#preprocessing\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "#vader\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "#spacy\n",
    "nlp2 = eng_spacysentiment.load()\n",
    "\n",
    "#bert\n",
    "MODEL_NAME = \"nlptown/bert-base-multilingual-uncased-sentiment\"  # Utile perché dovrebbe funzionare anche in italiano\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "\n",
    "#distilbert\n",
    "MODEL_NAME2 = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(MODEL_NAME2)\n",
    "model2 = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\W+', ' ', text)\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if token.text not in stop_words and not token.is_punct]\n",
    "    return tokens\n",
    "\n",
    "df = pd.read_csv('./csv_chunks_en_filtered.csv')\n",
    "\n",
    "df['tokens'] = df['chunk'].apply(preprocess)\n",
    "\n",
    "emotion_mapping = {\n",
    "    'anger': 'anger',\n",
    "    'anticipation': 'anticipation',\n",
    "    'disgust': 'disgust',\n",
    "    'fear': 'fear',\n",
    "    'joy': 'joy',\n",
    "    'sadness': 'sadness',\n",
    "    'surprise': 'surprise',\n",
    "    'trust': 'trust',\n",
    "    'anticip': 'anticipation',\n",
    "    'positive': 'positive',\n",
    "    'negative': 'negative'\n",
    "}\n",
    "\n",
    "final_emotions = list(set(emotion_mapping.values()))\n",
    "\n",
    "def sentiment_NCR(tokens):\n",
    "    total_emotions = {emotion: 0 for emotion in final_emotions}\n",
    "    emotion_count = 0\n",
    "    \n",
    "    for text in tokens:\n",
    "        emotion = NRCLex(text)\n",
    "        total_score = sum(emotion.affect_frequencies.values())\n",
    "    \n",
    "        if total_score > 0:\n",
    "            normalized_emotions = {emotion_mapping.get(emotion_name, None): emotion_score / total_score\n",
    "                                for emotion_name, emotion_score in emotion.affect_frequencies.items()\n",
    "                                if emotion_mapping.get(emotion_name, None)}\n",
    "            \n",
    "            for emotion_name, normalized_score in normalized_emotions.items():\n",
    "                total_emotions[emotion_name] += normalized_score\n",
    "            \n",
    "            emotion_count += 1\n",
    "\n",
    "    average_emotions = {emotion_name: (score / emotion_count) if emotion_count > 0 else 0\n",
    "                        for emotion_name, score in total_emotions.items()}\n",
    "    \n",
    "    total_sum = sum(average_emotions.values())\n",
    "    if total_sum > 0:\n",
    "        average_emotions = {key: round(value / total_sum, 3) for key, value in average_emotions.items()}\n",
    "    \n",
    "    return average_emotions\n",
    "\n",
    "df[final_emotions] = df['tokens'].apply(sentiment_NCR).apply(pd.Series)\n",
    "\n",
    "df['strongest_emotion'] = df[final_emotions].idxmax(axis=1)\n",
    "df['tot_pos'] = df[['joy', 'trust', 'positive', 'surprise', 'anticipation']].sum(axis=1)\n",
    "df['tot_neg'] = df[['sadness', 'disgust', 'fear', 'anger', 'negative']].sum(axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_VADER(testo):\n",
    "    sentiment = analyzer.polarity_scores(testo)\n",
    "    return sentiment['pos'], sentiment['neg'], sentiment['neu'], sentiment['compound']\n",
    "\n",
    "df = pd.read_csv('csv_chunks_en_filtered.csv')\n",
    "\n",
    "df[['pos', 'neg', 'neu', 'polarità']] = df['chunk'].apply(lambda x: pd.Series(sentiment_VADER(x)))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_textblob_def(testo):\n",
    "    blob = TextBlob(testo, analyzer=PatternAnalyzer())\n",
    "    polarità = blob.sentiment.polarity \n",
    "    soggettività = blob.sentiment.subjectivity\n",
    "    return polarità, soggettività\n",
    "\n",
    "print('Done :)')\n",
    "\n",
    "def sentiment_textblob_bayes(testo):\n",
    "    blob = TextBlob(testo, analyzer=NaiveBayesAnalyzer())\n",
    "    classificazione = blob.sentiment.classification  \n",
    "    p_pos = blob.sentiment.p_pos \n",
    "    p_neg = blob.sentiment.p_neg\n",
    "    return classificazione, p_pos, p_neg\n",
    "\n",
    "df = pd.read_csv('csv_chunks_en_filtered.csv')\n",
    "\n",
    "df[['polarità', 'soggettività']] = df['chunk'].apply(lambda x: pd.Series(sentiment_textblob_def(x)))\n",
    "df[['classificazione', 'p_pos', 'p_neg']] = df['chunk'].apply(lambda x: pd.Series(sentiment_textblob_bayes(x)))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_spacy(text):\n",
    "    doc = nlp2(text)\n",
    "    return doc.cats\n",
    "\n",
    "df = pd.read_csv('csv_chunks_en_filtered.csv')\n",
    "\n",
    "df[['positive','negative', 'neutral']] = df['chunk'].apply(sentiment_spacy).apply(pd.Series)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_bert(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    probs = softmax(outputs.logits, dim=-1).squeeze().tolist()\n",
    "    \n",
    "    sentiment_scores = {\n",
    "        \"very_negative\": probs[0],\n",
    "        \"negative\": probs[1],\n",
    "        \"neutral\": probs[2],\n",
    "        \"positive\": probs[3],\n",
    "        \"very_positive\": probs[4]\n",
    "    }\n",
    "    \n",
    "    return sentiment_scores\n",
    "\n",
    "df = pd.read_csv('csv_chunks_en_filtered.csv')\n",
    "\n",
    "df = df.join(df['chunk'].apply(sentiment_bert).apply(pd.Series))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_distilbert(text):\n",
    "    inputs = tokenizer2(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model2(**inputs)\n",
    "    probs = softmax(outputs.logits, dim=-1).squeeze().tolist()\n",
    "    \n",
    "    sentiment_scores = {\n",
    "        \"negative\": probs[0],\n",
    "        \"positive\": probs[1]\n",
    "    }\n",
    "    \n",
    "    return sentiment_scores\n",
    "\n",
    "df = pd.read_csv('csv_chunks_en_filtered.csv')\n",
    "\n",
    "df = df.join(df['chunk'].apply(sentiment_distilbert).apply(pd.Series))\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
